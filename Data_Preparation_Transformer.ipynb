{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d18bb-1822-49e4-b87b-12438e40cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa6a777-d04a-4ffe-947a-02f237d68f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff80de-1e6b-48c2-a7ed-0113ce0ef61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import tqdm\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1348478-ddb8-4bf7-8d1c-64c77bc5c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### check the installed version of PyTorch and CUDA #####\n",
    "torch_version = torch.__version__\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "cuda_version = torch.version.cuda if cuda_available else 'not available'\n",
    "\n",
    "torch_version, cuda_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee35e76-570e-46bb-baf4-4cbae5244dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### maximize column display #####\n",
    "pd.set_option('display.max_colwidth', None)     # display all content within each cell without truncation\n",
    "pd.set_option('display.max_columns', None)      # display all columns\n",
    "pd.set_option('display.width', None)            # ensure entire width of DataFrame is displayed\n",
    "\n",
    "pd.set_option('display.max_rows', None)         # display all rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c599066-12ad-4c9f-bac2-4d8b0dc003c2",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ffd8fb-2c29-41ee-a819-346907f908bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'..\\Transformer\\data\\input\\*.csv'\n",
    "path_csv = [p for p in glob.glob(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5e598d-c1b4-43c6-b2c1-c764b6953fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce8ee97-8a67-4e19-a04f-3fc2c6275c7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test(data):\n",
    "    \n",
    "    #Creating Categorical Variable for left and right shoulder width\n",
    "    data['RightShoulderWidthCat'] = 0\n",
    "    data.loc[data['RightShoulderWidth'] > 10, 'RightShoulderWidthCat'] = 1\n",
    "    data['LeftShoulderWidthCat'] = 0\n",
    "    data.loc[data['LeftShoulderWidth'] > 5, 'LeftShoulderWidthCat'] = 1\n",
    "    data['Seg_BO'] = 1\n",
    "    data.loc[data['SegmentType'] == 1, 'Seg_BO'] = 0\n",
    "\n",
    "\n",
    "    #data = pd.concat([data, pd.get_dummies(data.SegmentType, drop_first=True)], axis=1)\n",
    "    \n",
    "    data['Ln_Crash_Precursor_SPF'] =  np.log(data['Crash_Precursor_SPFs'])\n",
    "    data = data.drop(columns=['RightShoulderWidth', 'LeftShoulderWidth', 'SegmentType', 'Crash_Precursor_SPFs'])\n",
    "\n",
    "    dict = {'LeftShoulderWidthCat': 'LeftShoulderWidth',\n",
    "        'RightShoulderWidthCat': 'RightShoulderWidth',\n",
    "        'Seg_BO': 'SegmentType'\n",
    "       # 'Pred_Xgboost': 'Crash_Precursor_SPF',\n",
    "        \n",
    "        }\n",
    " \n",
    "    data.rename(columns=dict, inplace=True)\n",
    "\n",
    "    data['measurement_start'] = pd.to_datetime(data.measurement_start)\n",
    "    \n",
    "    data.sort_values(by=['SegmentId', 'measurement_start'], inplace=True)\n",
    "    \n",
    "    #data.drop(columns='SegmentType', inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    \n",
    "    # scale data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    columns = data.columns.drop(['measurement_start', 'Crash_Prediction_Index', 'SegmentId'])\n",
    "\n",
    "    data = pd.concat([data[['measurement_start', 'Crash_Prediction_Index', 'SegmentId']], \n",
    "                            pd.DataFrame(scaler.fit_transform(data[columns]), columns=columns)], axis=1)\n",
    "    \n",
    "    \n",
    "    # filter\n",
    "    #data = data[(data.measurement_start >= pd.Timestamp('2020-01-01 00:00:00')) & \n",
    "    #            (data.measurement_start <= pd.Timestamp('2022-12-31 11:59:59'))].reset_index(drop=True)\n",
    "    \n",
    "    data = data[data.Crash_Prediction_Index.isin([0, 1])].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # sequence numbering\n",
    "    difference = data.measurement_start.diff().dt.total_seconds().div(60).fillna(0).astype(int)\n",
    "    \n",
    "    data['sequenceNo'] = (difference > 1).cumsum() + 1\n",
    "    \n",
    "    data['month'] = data.measurement_start.dt.month\n",
    "\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # split in train and test data on months\n",
    "    train, test = data[~data.month.isin([10, 11, 12])].reset_index(drop=True), data[data.month.isin([10, 11, 12])].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9d2bdf-b801-49b3-bf13-89ad33ed5f91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### function to create sequences #####\n",
    "def create_sequences(X, y, window):\n",
    "    \n",
    "    X_sequences, y_sequences = [], []\n",
    "\n",
    "    for i in range(X.shape[0] - window):\n",
    "\n",
    "        X_sequences.append(X.values[i:(i + window)])\n",
    "        y_sequences.append(y.values[(i + window) - 1])\n",
    "\n",
    "        \n",
    "    return np.array(X_sequences), np.array(y_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c41f45-973e-4ea6-91a4-81ae30c38dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_sequencing(data, sequence_column, drop_columns, target_column, window):\n",
    "    \n",
    "    sequence_nos = sorted(list(data[sequence_column].unique()))\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for sequence_no in sequence_nos:\n",
    "\n",
    "        data_temp = data[data.sequenceNo == sequence_no].reset_index(drop=True)\n",
    "        \n",
    "        if data_temp.shape[0] < window:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        X_temp, y_temp = create_sequences(X=data_temp.drop(columns=drop_columns), y=data_temp[[target_column]], \n",
    "                                          window=window)\n",
    "        \n",
    "        X.append(X_temp); y.append(y_temp)\n",
    "        \n",
    "        \n",
    "    return np.vstack(X), np.vstack(y)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b4ede-7585-44cb-92d0-c3ae87e39fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(path_input, path_output, window, cuda=True):\n",
    "\n",
    "    df_input = pd.read_csv(path_input, low_memory=True,\n",
    "                usecols = ['SegmentId', 'measurement_start',\n",
    "                    '5min_avg_speed', '5min_std_speed',\n",
    "                   '5min_cv_speed', '5min_avg_volume', '5min_std_volume', '5min_cv_volume',\n",
    "                   '5min_avg_occupancy', '5min_std_occupancy', '5min_cv_occupancy',\n",
    "                    '5min_avg_speed_upstream', '5min_std_speed_upstream',\n",
    "                   '5min_cv_speed_upstream', '5min_avg_volume_upstream',\n",
    "                   '5min_std_volume_upstream', '5min_cv_volume_upstream',\n",
    "                   '5min_avg_occupancy_upstream', '5min_std_occupancy_upstream',\n",
    "                   '5min_cv_occupancy_upstream', '5min_avg_speed_downstream',\n",
    "                   '5min_std_speed_downstream', '5min_cv_speed_downstream',\n",
    "                   '5min_avg_volume_downstream', '5min_std_volume_downstream',\n",
    "                   '5min_cv_volume_downstream', '5min_avg_occupancy_downstream',\n",
    "                   '5min_std_occupancy_downstream', '5min_cv_occupancy_downstream', 'Segment Length',\n",
    "                   'ThruLanes', 'SegmentType', 'RightShoulderWidth', 'LeftShoulderWidth',\n",
    "                    'Turnout', 'Temperature', 'Relative Humidity', 'Wind Speed', 'Cloud Cover', \n",
    "                     'Precipitation', 'Snow Depth', 'Visibility',  'Diff_Avg_Volume',\n",
    "                       'Diff_Avg_Occupancy', 'Diff_Std_Occupancy', 'Diff_CV_Occupancy', 'Diff_Avg_Speed', \n",
    "                    'Diff_Std_Speed', 'Diff_CV_Speed', 'Crash_Precursor_SPFs', 'Day', 'Crash_Prediction_Index'])\n",
    "\n",
    "    df_input = df_input.dropna()\n",
    "\n",
    "    df_train, df_test = train_test(data=df_input)\n",
    "    \n",
    "    \n",
    "    X_train, y_train = data_sequencing(data=df_train, sequence_column='sequenceNo',\n",
    "                                       drop_columns=['measurement_start', 'Crash_Prediction_Index', 'SegmentId', 'sequenceNo', 'month'], \n",
    "                                       target_column='Crash_Prediction_Index', window=window)\n",
    "    \n",
    "    X_test, y_test = data_sequencing(data=df_test, sequence_column='sequenceNo',\n",
    "                                     drop_columns=['measurement_start', 'Crash_Prediction_Index', 'SegmentId', 'sequenceNo', 'month'], \n",
    "                                     target_column='Crash_Prediction_Index', window=window)\n",
    "\n",
    "\n",
    "    # convert to pytorch tensors\n",
    "    X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    \n",
    "    # move tensors to gpu if cuda is available\n",
    "    if cuda and torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        \n",
    "        X_train, y_train, X_test, y_test = X_train.to(device), y_train.to(device), X_test.to(device), y_test.to(device)\n",
    "        \n",
    "\n",
    "    # append to the master file\n",
    "    if os.path.exists(path_output):\n",
    "        df_output = torch.load(path_output)\n",
    "        \n",
    "        output_X_train, output_y_train, output_X_test, output_y_test = df_output\n",
    "\n",
    "        # concatenate new data with existing data\n",
    "        X_train, y_train = torch.cat((output_X_train, X_train), 0), torch.cat((output_y_train, y_train), 0)\n",
    "        X_test, y_test = torch.cat((output_X_test, X_test), 0), torch.cat((output_y_test, y_test), 0)\n",
    "\n",
    "        \n",
    "    # save the concatenated data\n",
    "    torch.save((X_train, y_train, X_test, y_test), path_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea0664-e10a-4de9-987f-3a57a829f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output = '..\\Transformer\\data\\output\\data_sequence_pm.pt'\n",
    "\n",
    "for i in tqdm.tqdm(range(len(path_csv))):\n",
    "    \n",
    "    data_preparation(path_input=path_csv[i], path_output=path_output, window=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
